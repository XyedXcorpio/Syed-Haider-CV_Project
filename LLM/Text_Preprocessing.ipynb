{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Objective:**  \n",
        "In this lab, you will learn how to generate synthetic text data (e.g., product reviews) using GPT‑2 from Hugging Face, perform basic data analysis, and anonymize personal data in text using regular expressions.\n",
        "\n",
        "### **Tasks Covered:**\n",
        "1. Loading a pre-trained GPT‑2 model and tokenizer.\n",
        "2. Creating a text generation function that produces synthetic reviews.\n",
        "3. Generating synthetic reviews from a list of prompts.\n",
        "4. Storing the generated reviews in a CSV file.\n",
        "5. Computing and displaying basic statistics on the synthetic reviews.\n",
        "6. Writing and testing simple regex patterns to detect personal data (e.g., email addresses, phone numbers, and full names).\n",
        "7. Anonymizing detected personal data by replacing or masking it with placeholders (e.g., `[EMAIL]`, `[PHONE]`, or masked names).\n",
        "8. Integrating the anonymization process into the synthetic review analysis pipeline.\n",
        "\n",
        "### **Prerequisites:**  \n",
        "- Python 3.7+  \n",
        "- PyTorch and Transformers libraries (install via `pip install torch transformers`)  \n",
        "- Pandas library (install via `pip install pandas`)  \n",
        "\n",
        "### **Instructions:**\n",
        "- Run each cell sequentially.\n",
        "- Read the markdown instructions before each code cell.\n",
        "- Ensure your implementations for both text generation and data anonymization work as expected.\n"
      ],
      "metadata": {
        "id": "-WSztv1asGhB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Load the GPT‑2 Model and Tokenizer [DO NOT EDIT]"
      ],
      "metadata": {
        "id": "mCJGU2FMs1Va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Specify the model name\n",
        "model_name = \"gpt2\"\n",
        "\n",
        "# Load the tokenizer and model from Hugging Face\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "model.eval()  # Set the model to evaluation mode"
      ],
      "metadata": {
        "id": "8BvRTRpHsMi_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e059ed4-9726-4584-a2c3-4d7ef083d383"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Define a Text Generation Function [DO NOT EDIT]\n",
        "\n",
        "In this step, we define a function `generate_text` that takes a prompt and generates text using GPT‑2.  "
      ],
      "metadata": {
        "id": "RGsXSCtfs95U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(prompt, max_length=50, temperature=0.7, top_k=50, top_p=0.95):\n",
        "    \"\"\"\n",
        "    Generate text using GPT-2 given an input prompt.\n",
        "    \"\"\"\n",
        "    # Encode the input prompt\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "    # Generate text using the model\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            input_ids,\n",
        "            max_length=max_length,\n",
        "            do_sample=True,\n",
        "            temperature=temperature,\n",
        "            top_k=top_k,\n",
        "            top_p=top_p,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "    # Decode the generated tokens to a string\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "fFjSf9_WhuOA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Test the Text Generation Function [DO NOT EDIT]\n",
        "\n",
        "Here, we test the `generate_text` function with a sample prompt for a product review.  \n",
        "Review the output in the console to ensure that the model generates a detailed review."
      ],
      "metadata": {
        "id": "-qscN2Lstal3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prompt\n",
        "prompt = \"Write a detailed review for a smartphone:\"\n",
        "generated_review = generate_text(prompt, max_length=100)\n",
        "print(\"Generated Review:\\n\", generated_review)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shsKhCGojusv",
        "outputId": "f524425d-b51d-4d01-eac3-e14dd99493a5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Review:\n",
            " Write a detailed review for a smartphone:\n",
            "\n",
            "Why this review is important\n",
            "\n",
            "The HTC One M9 is the most powerful smartphone we've ever tested. It's a smart, low-cost smartphone that is easy to use, and it's also easily the most customizable. It's also a very good phone for anyone who likes to be a smartphone user. That said, it's not the most powerful phone that we've tested, so it's not a great phone for most people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Generate a Synthetic Dataset [DO NOT EDIT]\n",
        "\n",
        "In this step, we will generate multiple synthetic reviews using a variety of prompts.  \n",
        "We define a list of sample prompts and generate a specified number of reviews.  \n",
        "The generated reviews are stored in a Pandas DataFrame.\n",
        "\n",
        "### **Instructions:**  \n",
        "- You can adjust the `num_samples` variable to generate more or fewer reviews.\n",
        "- Run the cell and review the first few generated reviews printed from the DataFrame."
      ],
      "metadata": {
        "id": "d_dGkCfeI3jL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# List of sample prompts\n",
        "prompts = [\n",
        "    \"Write a detailed review for a new smartphone:\",\n",
        "    \"Describe your experience with a recently launched laptop:\",\n",
        "    \"Give a review of a new pair of wireless headphones:\",\n",
        "    \"Share your thoughts on a cutting-edge smartwatch:\"\n",
        "]\n",
        "\n",
        "# Number of synthetic examples to generate\n",
        "num_samples = 5\n",
        "synthetic_reviews = []\n",
        "\n",
        "for _ in range(num_samples):\n",
        "    # Randomly choose a prompt for variety\n",
        "    prompt = random.choice(prompts)\n",
        "    review = generate_text(prompt, max_length=100)\n",
        "    synthetic_reviews.append(review)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(synthetic_reviews, columns=[\"Review\"])\n",
        "print(\"First 5 synthetic reviews:\")\n",
        "print(df.head())\n",
        "print(df['Review'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56Xjod7djxbM",
        "outputId": "2a1c96ea-a68c-4c3b-815e-1839cc2a4236"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 synthetic reviews:\n",
            "                                              Review\n",
            "0  Share your thoughts on a cutting-edge smartwat...\n",
            "1  Write a detailed review for a new smartphone:\\...\n",
            "2  Describe your experience with a recently launc...\n",
            "3  Describe your experience with a recently launc...\n",
            "4  Describe your experience with a recently launc...\n",
            "0    Share your thoughts on a cutting-edge smartwat...\n",
            "1    Write a detailed review for a new smartphone:\\...\n",
            "2    Describe your experience with a recently launc...\n",
            "3    Describe your experience with a recently launc...\n",
            "4    Describe your experience with a recently launc...\n",
            "Name: Review, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Save the Dataset & Compute Statistics [to be solved]\n",
        "### **Instructions:**\n",
        "- Save the DataFrame:\n",
        "- Save your synthetic reviews to synthetic_reviews.csv (without the index).\n",
        "\n",
        "### **Compute Statistics:**\n",
        "- Calculate the total number of reviews.\n",
        "- Compute the average review length in words."
      ],
      "metadata": {
        "id": "jYFjgaRTrSV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the DataFrame in a CSV file\n",
        "df.to_csv(\"synthetic_reviews.csv\", index=False)\n",
        "\n",
        "# Compute basic statistics on synthetic data\n",
        "num_reviews = len(df)\n",
        "df['Review_Length'] = df['Review'].apply(lambda x : len(x.split()))\n",
        "avg_length = df['Review_Length'].mean()\n",
        "# Calculate total number of reviews\n",
        "\n",
        "\n",
        "# Calculate average review length (in words)\n",
        "# Ensure that each review is treated as a string\n",
        "df['Review'] = df['Review'].astype(str)\n",
        "\n",
        "\n",
        "print(f\"\\nTotal number of reviews: {num_reviews}\")\n",
        "print(f\"Average review length: {avg_length:.2f} words\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bExqbOAgjxdh",
        "outputId": "7f8f8cdb-5a2e-44d8-9af5-c038831cc555"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total number of reviews: 5\n",
            "Average review length: 72.20 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exploring Regular Expressions[to be solved]\n",
        "\n",
        "**Objective**: Write and test simple regex patterns using Python.\n",
        "\n",
        "**Instructions**:\n",
        "\n",
        "\n",
        "Write code that uses re.search() or re.findall() to locate:\n",
        "\n",
        " - An email address\n",
        "\n",
        " - A phone number\n",
        "\n",
        " - A full name pattern (e.g., two words starting with capital letters)\n"
      ],
      "metadata": {
        "id": "ylsSaounXneI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Sample text strings\n",
        "email_text = \"Please contact ali@gmail.com for further details.\"\n",
        "phone_text = \"My phone number is +923034567890.\"\n",
        "name_text  = \"Hello, my name is Abdullah Asghar.\"\n",
        "\n",
        "# Define regex patterns\n",
        "email_pattern = r\"[a-zA-Z0-9._-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,5}\"  # Matches standard emails\\\n",
        "phone_pattern = r\"\\+92\\d{10}\"  # Matches phone numbers in the format +923034567890\n",
        "\n",
        "#Add regex for phone number and Name\n",
        "#phone_pattern = r\"\"  # Matches phone numbers like +923034567890\n",
        "name_pattern  = r\"\\b[A-Z][a-z]+\\s[A-Z][a-z]+\\b\"  # Matches two words starting with uppercase letters\n",
        "\n",
        "# Perform searches\n",
        "email_match = re.search(email_pattern, email_text)\n",
        "phone_match = re.search(phone_pattern, phone_text)\n",
        "name_match = re.search(name_pattern, name_text)\n",
        "\n",
        "\n",
        "print(\"Email Found:\", email_match.group() if email_match else \"None\")\n",
        "print(\"Phone Found:\", phone_match.group() if phone_match else \"None\")\n",
        "print(\"Name Found: \", name_match.group() if name_match else \"None\")"
      ],
      "metadata": {
        "id": "vKsIUshPWVyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28110079-87b1-4f89-b2e0-2e74f57afc26"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Email Found: ali@gmail.com\n",
            "Phone Found: +923034567890\n",
            "Name Found:  Abdullah Asghar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Anonymizing Personal Data with Regex[To be solved]\n",
        "\n",
        "**Objective:**  \n",
        "Anonymize emails, phone numbers, and full names in a text using Python regex.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Email Anonymization:\n",
        "   - Use a regex to find email\n",
        "   - Replace matches with `[EMAIL]` via `re.sub()`.\n",
        "\n",
        "2. Phone Number Anonymization:\n",
        "   - Use a regex to find number.\n",
        "   - Replace matches with `[PHONE]` via `re.sub()`.\n",
        "\n",
        "3. Name Anonymization:\n",
        "   - Use a regex to find name.\n",
        "   - Replace matches with a masked version (e.g., \"John Doe\" → \"J**** D****\") via `re.sub()`.\n",
        "\n"
      ],
      "metadata": {
        "id": "4s1XcqcGZQX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Example containing personal data\n",
        "text = \"\"\"\n",
        "Abdullah's email is abde@example.com and his phone number is +923034567890.\n",
        "He lives at 123 Raya St, Springfield and his colleague Ali Smith has the email Ali.smith@company.org.\n",
        "\"\"\"\n",
        "\n",
        "# Anonymize email addresses\n",
        "email_pattern = r\"[a-zA-Z0-9._-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,5}\"\n",
        "text = re.sub(email_pattern, '[EMAIL]', text)\n",
        "#email_pattern = r\"\"\n",
        "\n",
        "\n",
        "# Anonymize phone numbers (a simple version that matches numbers with optional + and separators)\n",
        "phone_pattern = r\"\\+?\\d[\\d\\s-]{7,}\\d\"\n",
        "text = re.sub(phone_pattern, '[PHONE]', text)\n",
        "\n",
        "\n",
        "\n",
        "# Anonymize names:\n",
        "# This example assumes a name is two words that start with capital letters.\n",
        "# It replaces each name with a masked version showing only the first letter of each part.\n",
        "def mask_name(match):\n",
        "    #Code here\n",
        "    name = match.group()\n",
        "    part = name.split()\n",
        "    first_initial = part[0][0]\n",
        "    second_initial = part[1][0]\n",
        "    return f\"{first_initial}**** {second_initial}****\"\n",
        "\n",
        "name_pattern = r\"\\b[A-Z][a-z]+\\s[A-Z][a-z]+\\b\"\n",
        "text = re.sub(name_pattern, mask_name, text)\n",
        "\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hVJLlbbWV01",
        "outputId": "29286425-8a2a-4b39-fd50-5141a1b7d09b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Abdullah's email is [EMAIL] and his phone number is [PHONE].\n",
            "He lives at 123 R**** S****, Springfield and his colleague A**** S**** has the email [EMAIL].\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Extracting Course Codes Using spaCy [To be solved]\n",
        "\n",
        "**Objective:**\n",
        "\n",
        "Extract course codes from text that contains course descriptions using spaCy tokenization instead of regex.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        " - Load spaCy Model:\n",
        "\t Use spacy.load('en_core_web_sm') to load the English NLP model.\n",
        " - Tokenize Course Descriptions:\n",
        "\t Process text with nlp(), and extract individual tokens.\n",
        " - Identify Course Codes:\n",
        "\t Find patterns where:\n",
        "\t The first token consists of uppercase letters (Department Code).\n",
        "\t The second token is a three-digit number (Course Number).\n",
        " - Extract and Return Course Code:\n",
        "\t  Concatenate the department and course number (e.g., \"CS\" + \"101\" → \"CS101\")."
      ],
      "metadata": {
        "id": "cBWK0NpHlcKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Sample data\n",
        "course_descriptions = [\n",
        "    \"CS 101 Introduction to Computer Science\",\n",
        "    \"MATH 202 Calculus II\",\n",
        "    \"ENG 150 English Literature\",\n",
        "    \"BIO 303 Genetics and Evolution\",\n",
        "    \"HIST 210 World History\"\n",
        "]\n",
        "\n",
        "# Load the spaCy English model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def extract_course_code(text):\n",
        "    doc = nlp(text)\n",
        "    print(doc)\n",
        "    tokens = [token.text for token in doc]\n",
        "\n",
        "\n",
        "    if len(tokens) > 1 and tokens[0].isalpha() and tokens[0].isupper() and tokens[1].isdigit() and len(tokens[1]) == 3:\n",
        "        return tokens[0] + tokens[1]\n",
        "    return None\n",
        "\n",
        "# Iterate through the course descriptions\n",
        "for description in course_descriptions:\n",
        "    course_code = extract_course_code(description)\n",
        "    if course_code:\n",
        "        print(f\"Extracted Course Code: {course_code}\")\n",
        "    else:\n",
        "        print(\"No course code found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNy5VVjGjuxt",
        "outputId": "b33f63af-444f-441b-9fcd-feddeb1d0c85"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CS 101 Introduction to Computer Science\n",
            "Extracted Course Code: CS101\n",
            "MATH 202 Calculus II\n",
            "Extracted Course Code: MATH202\n",
            "ENG 150 English Literature\n",
            "Extracted Course Code: ENG150\n",
            "BIO 303 Genetics and Evolution\n",
            "Extracted Course Code: BIO303\n",
            "HIST 210 World History\n",
            "Extracted Course Code: HIST210\n"
          ]
        }
      ]
    }
  ]
}